{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像処理100本ノック\n",
    "\n",
    "画像処理のアルゴリズムを理解するための100本ノックです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCVとは\n",
    "\n",
    "本節では、OpenCVについて詳しく解説していきます。OpenCVの概要について説明したのち、OpenCVの主な機能を紹介します。また、PillowやScikit-imageなどの他の画像処理系ライブラリとの比較も行います。\n",
    "\n",
    "### OpenCVの概要\n",
    "\n",
    "OpenCVは、その名の通りオープンソースのコンピュータビジョン用ライブラリです。コンピュータビジョンは、コンピュータによる視覚についての研究分野の名称ですが、画像認識とほぼ同義と考えていただければわかりやすいかと思います。OpenCVは、元々はインテルが開発したプログラムで、現在でも開発が進められています。ごく一部のアルゴリズムは特許を取得されているため、それらを商用利用する際には確認が必要ですが、基本的に無料で利用することができ、商用利用も可能です。また、クロスプラットフォームのライブラリで、Linux、MacOS、Windowsや、iOS、AndroidといったOSとC++、Python、Javaの三つのプログラミング言語に対応しているため、あまり環境の制約を受けることなく活用することができます。\n",
    "\n",
    "### OpenCVの主な機能\n",
    "\n",
    "OpenCVの主な機能について見ていきましょう。本稿では、OpenCVの主な機能を以下の５つに大別して解説します。\n",
    "\n",
    "- 画像と動画の読み込み / 表示 / 保存\n",
    "- 画像処理\n",
    "- 機械学習\n",
    "- 検出（画像認識）\n",
    "- 三次元の処理\n",
    "\n",
    "#### 画像と動画の読み込み・表示・保存\n",
    "画像を扱うためには画像を表示したり保存したりする機能がなければいけません。OpenCVにはこれらの基本的な機能は当然搭載されています。また、動画を扱うための機能や、図形や文字などを描画する機能もあり、様々な素材を扱うことができます。\n",
    "\n",
    "#### 画像処理\n",
    "OpenCVで実行可能な画像処理の例として以下のようなものが挙げられます。本稿後半の実装では、犬の画像を用いて様々な画像処理を行いますので、ご期待ください。\n",
    "\n",
    "- 色変換<br>\n",
    "カラー画像をグレースケール画像にしたり、BGR（Blue, Green, Red）で表示されている画像の色をRGB（Red, Green, Blue）に変換したりと、様々な変換方法があります。単に色を変換するだけでなく、他の処理と組み合わせることによって、画像内にある特定の色の物体を検出することなどもできます。\n",
    "\n",
    "- 幾何変換（拡大・縮小・回転など）<br>\n",
    "画像を拡大・縮小したり、回転させたりすることができます。一見大したことのない処理に思えますが、物体検出の際に画像の向きや大きさなどを変えるだけでも検出の成否が変わることもあるため、重要な処理手法です。\n",
    "\n",
    "- しきい値処理<br>\n",
    "グレースケール化された画像において、設定されたしきい値よりピクセルの値が大きい場合と小さい場合で別々の値を割り当てることで画像を変換する手法です。説明だけではイメージしづらいかと思いますので、後半の実装を確認してください。\n",
    "\n",
    "- 平滑化<br>\n",
    "平滑化は、端的に言えばぼかしを入れる処理手法です。ぼかしの入れ方にも様々な手法があり、適切な手法を用いることで画像内のノイズを除去することができます。\n",
    "\n",
    "- モルフォロジー変換<br>\n",
    "主に色が二種類の画像（二値画像）に対して行う処理で、画像上に写っている物体を膨張させたり縮小させたりすることができます。これも、平滑化と同様にノイズ除去に活用できます。\n",
    "\n",
    "- 部分的な復元<br>\n",
    "落書きや傷がある写真などにおいて、周辺の画素の情報からその部分を復元するといった処理も可能です。\n",
    "\n",
    "#### 機械学習\n",
    "OpenCVには、機械学習の機能も含まれています。OpenCVで活用できる手法はk近傍法、サポートベクターマシン、K-Meansクラスタリングで、これらの手法を文字分類や画像処理に活用することができます。例えば、クラスタリングの手法を用いて画像に含まれる色のデータを複数のクラスターに分けることで、色の種類を減らす処理なども可能です。\n",
    "\n",
    "#### 検出（画像認識）\n",
    "画像中の様々なものを検出・認識する機能としては以下のようなものがあります。\n",
    "\n",
    "- 直線・円の検出\n",
    "- エッジ検出<br>\n",
    "エッジとは、輝度が大きく変化する点のことで、物体の輪郭などがそれに当たります。\n",
    "- 物体検出<br>\n",
    "画像中の物体を検出するいわゆる画像認識の機能です。顔や目など、基本的な物体については分類器がOpenCV内に用意されている上、学習に必要な大量の画像データさえ集めることができれば、自分で検出したい物体用の分類器を作ることもできます。\n",
    "\n",
    "#### 三次元の処理\n",
    "さらに、OpenCVでは二次元の画像データから三次元の情報を推測し、以下のような処理をすることができます。\n",
    "- 画像の歪みの補正\n",
    "- 画像中に三次元の物体を描画\n",
    "- 複数枚の二次元画像から実際の距離を推測\n",
    "\n",
    "以上がOpenCVの主な機能です。ここに紹介しているものだけでも様々なことができますが、これでもOpenCVの機能の一部にすぎません。\n",
    "\n",
    "### 関連のあるライブラリ\n",
    "#### NumPy\n",
    "画像データは数値データの集まりなので、数値計算ライブラリとしてよく知られているNumPy（読み：ナンパイ）も画像処理に活用することができます。単色化や減色などの処理が可能ですが、NumPyだけでは画像を読み込めないため、OpenCVやPillowといった画像の読み込みが可能なライブラリと併用する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリをインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをインポート\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# 画像の読み込み\n",
    "img = cv2.imread('./utils/onepiece01_luffy.png')\n",
    "img_noise = cv2.imread('./utils/onepiece01_luffy.png')\n",
    "# 画像保存\n",
    "OUT_DIR = './output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像を表示してみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCVの関数imread()で画像ファイルを読み込むと色の順番がBGR（青、緑、赤）になる。一方、matplotlibでは色の順番はRGB（赤、緑、青）を前提としています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そのため、matplotlibの関数とOpenCVの関数を両方使いたい場合はBGRとRGBを変換する必要があります"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCVの関数cvtColor()を使う方法と、単純にndarrayの順番を入れ替える方法があります。\n",
    "\n",
    "ここでは、以下の内容について説明します\n",
    "- OpenCVはBGR、matplotlibはRGB\n",
    "- OpenCVの関数cvtColor()でBGRとRGBを変換\n",
    "- cvtColor()を使わずにBGRとRGBを変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCVの関数cvtColor()を使うとRGBやBGR、HSVなど様々な色空間を相互に変換できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グレースケール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グレースケールとは、画像の輝度表現方法の一種であり下式で計算される。\n",
    "Grayscale = 0.2126 R + 0.7152 G + 0.0722 B\n",
    "\n",
    "それぞれの係数は人間の視覚の敏感さであり、Gに人間の最も強く反応し、Bにはあまり反応しないことを示す。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv\n",
    "img_gray = cv2.cvtColor(dst, cv2.COLOR_RGB2GRAY)\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('input')\n",
    "plt.imshow(dst)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('output')\n",
    "plt.imshow(img_gray, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二値化, Binarization\n",
    "二値化とは、画像を特定の値を閾値として黒と白の二値で表現する方法です。\n",
    "- グレースケール化\n",
    "- 閾値を128にして二値化します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.cvtColor(dst, cv2.COLOR_RGB2GRAY)\n",
    "th, img_bin = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('input')\n",
    "plt.imshow(dst)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('gray')\n",
    "plt.imshow(img_gray, cmap='gray')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('output')\n",
    "plt.imshow(img_bin, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 大津の二値化\n",
    "大津の二値化とは判別分析法と呼ばれ、二値化における分離の閾値を自動決定する教師なし手法です。 これはクラス内分散とクラス間分散の比から計算されます。\n",
    "\n",
    "まず、グレースケールの輝度値（ピクセルの値）のヒストグラムはいかになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(img_gray.ravel(), bins=255, rwidth=0.8, range=(0, 255))\n",
    "plt.text(0, 500, 'class0', fontsize=17)\n",
    "plt.text(200, 500, 'class1', fontsize=17)\n",
    "plt.vlines(120, 0, 700, color='red', linestyles='dotted')\n",
    "plt.xlabel('pixel')\n",
    "plt.ylabel('appearance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで赤線を閾値として、左側をクラス0、右側をクラス1として、この二つのクラスがバランスよく分離できれば良い二値化といえる。よって、クラス0と1の分離度を定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th, img_bin = cv2.threshold(img_gray, 0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "print('threshold >>', th)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('input')\n",
    "plt.imshow(dst)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('gray')\n",
    "plt.imshow(img_gray, cmap='gray')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('output')\n",
    "plt.imshow(img_bin, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSV変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HSV変換とは、Hue(色相)、Saturation(彩度)、Value(明度) で色を表現する手法です。\n",
    "\n",
    "- Saturation ... 色の鮮やかさ。\n",
    "- Saturationが低いと灰色さが顕著になり、くすんだ色となる。 ( 0 <= S < 1)\n",
    "- Value ... 色の明るさ。Valueが高いほど白に近く、Valueが低いほど黒に近くなる。 ( 0 <= V < 1)\n",
    "- Hue ... 色合いを0~360度で表現し、赤や青など色の種類を示す。 ( 0 <= H < 1) 色相は次の色に対応する。\n",
    "\n",
    "ここでHueをとるのとRGBをとるのは何が違うかというと、色成分をとる時に違う、RGBでは 万次元をとるため、緑を取りたいと思っても、範囲指定が複雑になる（G > 200 としてもRやBが200以上なら見た目が緑とは限らないから）。　逆にHueでは360次元で値をとるため、緑の指定が簡単になる。これを上手く活用できれば色成分の抽出が簡単に行えることあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "plt.figure(figsize=(12, 1))\n",
    "plt.title('Hue')\n",
    "for i in range(360):\n",
    "    plt.vlines(i, 0, 1, color=cm.hsv(i / 360))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv\n",
    "hsv = cv2.cvtColor(dst, cv2.COLOR_RGB2HSV) # RGB -> HSV\n",
    "hsv[..., 0] = (hsv[..., 0] + 90) % 180 # Hue of opencv is defined [0, 180]\n",
    "img_hsv = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB) # HSV -> RGB\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('input')\n",
    "plt.imshow(dst)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('output')\n",
    "plt.imshow(img_hsv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 減色, color subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "色の複雑さをある程度抑えることができ、味のある画像にもなります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_subtraction(img, div=4):\n",
    "    th = 256 // div\n",
    "    return np.clip(img // th * th + th // 2, 0, 255)\n",
    "\n",
    "img_sub = color_subtraction(dst) # color subtract\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('input')\n",
    "plt.imshow(dst)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('output')\n",
    "plt.imshow(img_sub)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 減色を8値にしてみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8値でも元の画像に相当近い見た目を保持できています、この時のRGBは なので、元の$1678万 = 256 ^ 3$に比べると色空間はかなり削減できています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sub = color_subtraction(dst, div=8) # color subtract\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('input')\n",
    "plt.imshow(dst)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('output')\n",
    "plt.imshow(img_sub)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# フィルタリング\n",
    "ここでは画像をグリッド分割(ある固定長の領域に分ける)し、かく領域内(セル)の平均値でその領域内の値を埋めます。 \n",
    "このようにグリッド分割し、その領域内の代表値を求める操作はPooling(プーリング) と呼ばれます\n",
    "これらプーリング操作はCNN(Convolutional Neural Network) において重要な役割を持ちます。\n",
    "\n",
    "平均プーリングは次式で定義される。ここでいうRはプーリングを行う領域である。\n",
    "つまり、3x3の領域でプーリングを行う。|R|=3x3=9となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_average(img, ksize_h=8, ksize_w=8):\n",
    "    _img = img.copy().astype(np.float32)\n",
    "    \n",
    "    # padding\n",
    "    h, w = img.shape[:2]\n",
    "    outer_h = h % ksize_h\n",
    "    pad_top = outer_h // 2\n",
    "    pad_bottom = outer_h - pad_top\n",
    "    outer_w = w % ksize_w\n",
    "    pad_left = outer_w // 2\n",
    "    pad_right = outer_w - pad_left\n",
    "    \n",
    "    _img = np.pad(_img, [(pad_top, pad_bottom), (pad_left, pad_right), (0, 0)], 'edge')\n",
    "    out = np.zeros_like(_img)\n",
    "    \n",
    "    new_h, new_w = out.shape[:2]\n",
    "    c = 1 if len(out.shape) == 2 else out.shape[2]\n",
    "    \n",
    "    # filtering\n",
    "    for iy in range(0, new_h, ksize_h):\n",
    "        for ix in range(0, new_w, ksize_w):\n",
    "            for ic in range(c):\n",
    "                out[iy : iy + ksize_h, ix : ix + ksize_w, ic] = _img[iy : iy + ksize_h, ix : ix + ksize_w, ic].mean()\n",
    "            \n",
    "    out = out[pad_top : pad_top + h, pad_left : pad_left + w]\n",
    "    return np.clip(out, 0, 255).astype(np.uint8)\n",
    "\n",
    "img_pool = pool_average(dst) # pooling\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('input')\n",
    "plt.imshow(dst)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('output')\n",
    "plt.imshow(img_pool)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## フィルタサイズを大きくすると"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フィルタサイズが大きくなると、ピンボケのような画像になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pool = pool_average(dst, ksize_h=16, ksize_w=16) # pooling\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('input')\n",
    "plt.imshow(dst)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('output')\n",
    "plt.imshow(img_pool)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最大プーリング, max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "平均値でなく、最大値を出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_max(img, ksize_h=8, ksize_w=8):\n",
    "    _img = img.copy().astype(np.float32)\n",
    "    \n",
    "    # padding\n",
    "    h, w = img.shape[:2]\n",
    "    outer_h = h % ksize_h\n",
    "    pad_top = outer_h // 2\n",
    "    pad_bottom = outer_h - pad_top\n",
    "    outer_w = w % ksize_w\n",
    "    pad_left = outer_w // 2\n",
    "    pad_right = outer_w - pad_left\n",
    "    \n",
    "    _img = np.pad(_img, [(pad_top, pad_bottom), (pad_left, pad_right), (0, 0)], 'edge')\n",
    "    out = np.zeros_like(_img)\n",
    "    \n",
    "    new_h, new_w = out.shape[:2]\n",
    "    c = 1 if len(out.shape) == 2 else out.shape[2]\n",
    "    \n",
    "    # filtering\n",
    "    for iy in range(0, new_h, ksize_h):\n",
    "        for ix in range(0, new_w, ksize_w):\n",
    "            for ic in range(c):\n",
    "                out[iy : iy + ksize_h, ix : ix + ksize_w, ic] = _img[iy : iy + ksize_h, ix : ix + ksize_w, ic].max()\n",
    "            \n",
    "    out = out[pad_top : pad_top + h, pad_left : pad_left + w]\n",
    "    return np.clip(out, 0, 255).astype(np.uint8)\n",
    "\n",
    "img_pool = pool_max(dst) # pooling\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('input')\n",
    "plt.imshow(dst)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('output')\n",
    "plt.imshow(img_pool)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ノイズ付与"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ノイズ画像の作成\n",
    "noise_level=150\n",
    "h,w,c=dst.shape\n",
    "noise=np.random.randint(0,noise_level,(h,w,3))\n",
    "img_noiz=dst + noise\n",
    "img_noiz=img_noiz.astype('int16').clip(0, 255)\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('input')\n",
    "plt.imshow(dst)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('output')\n",
    "plt.imshow(img_noiz)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ガウシアンフィルタ\n",
    "画像がノイズだらけになってしまった時にどうにかする方法としてガウシアンフィルタを実装してノイズを除去してみましょう\n",
    "\n",
    "ガウシアンフィルタとは画像の平滑化（滑らかにする）を行うフィルタの一種であり、ノイズ除去にも使われる。\n",
    "\n",
    "ガウシアンフィルタは注目画素の周辺画素を、ガウス分布による重み付けで平滑化し、次式で定義される。 このような重みはカーネルやフィルタと呼ばれる。\n",
    "\n",
    "ただし、画像の端はこのままではフィルタリングできないため、画素が足りない部分は0で埋める。これを0パディングと呼ぶ。 かつ、重みは正規化する。(sum g = 1)img_noiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gau = cv2.GaussianBlur(img_noiz, (3,3), 1.3)\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('input')\n",
    "plt.imshow(img_noiz)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('answer')\n",
    "plt.imshow(img_gau)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カーネルサイズや$\\sigma$を変えてみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カーネルサイズを大きくすると、画像がぼやける。逆にぼやけたことでノイズが分かりにくくなったと言える。\n",
    "を大きくすると、ノイズがかなり消えた。Gaussianの$\\sigma$は周辺との重みバランスが均衡化されるので、ノイズが消えやすくなった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_gaussian(img, ksize=(3, 3), sigma=1.3):\n",
    "    _img = img.copy().astype(np.float32)\n",
    "    ksize_h, ksize_w = ksize\n",
    "    \n",
    "    # padding\n",
    "    h, w = img.shape[:2]\n",
    "    pad_top, pad_bottom = ksize_h, ksize_h\n",
    "    pad_left, pad_right = ksize_w, ksize_w\n",
    "    \n",
    "    _img = np.pad(_img, [(pad_top, pad_bottom), (pad_left, pad_right), (0, 0)], 'edge')\n",
    "    out = np.zeros_like(_img)\n",
    "    \n",
    "    new_h, new_w = out.shape[:2]\n",
    "    c = 1 if len(out.shape) == 2 else out.shape[2]\n",
    "    \n",
    "    # prepare kernel\n",
    "    k = np.zeros([ksize_h, ksize_w])\n",
    "    for iy in range(ksize_h):\n",
    "        for ix in range(ksize_w):\n",
    "            k[iy, ix] = 1 / (2 * np.pi * (sigma ** 2)) * np.exp(- ((ix - ksize_w // 2) ** 2 + (iy - ksize_h // 2) ** 2) / (2 * sigma ** 2))\n",
    " \n",
    "    k /= k.sum()\n",
    "\n",
    "    # filtering\n",
    "    for iy in range(new_h - ksize_h):\n",
    "        for ix in range(new_w - ksize_w):\n",
    "            for ic in range(c):\n",
    "                out[iy, ix, ic] = np.sum(_img[iy : iy + ksize_h, ix : ix + ksize_w, ic] * k)\n",
    "            \n",
    "    out = out[pad_top : pad_top + h, pad_left : pad_left + w]\n",
    "    return np.clip(out, 0, 255).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title('input')\n",
    "plt.imshow(img_noiz)\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title('ksize=3')\n",
    "img_gau = filter_gaussian(img_noiz, (3, 3), 1.3)\n",
    "plt.imshow(img_gau)\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title('ksize = 7')\n",
    "img_gau = filter_gaussian(img_noiz, (7, 7), 1.3)\n",
    "plt.imshow(img_gau)\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title('sigma = 3')\n",
    "img_gau = filter_gaussian(img_noiz, (7, 7), 3)\n",
    "plt.imshow(img_gau)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussianについて\n",
    "sigmaが広がると、グラフが横広がりになる。つまり、 GaussianFilterでは重みが均一化されるので、Meanフィルタに近付く。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def gaussian(sigma):\n",
    "    x = np.arange(-8, 8, 0.1) \n",
    "    y = np.arange(-8, 8, 0.1)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    z = 1 / (2 * np.pi * (sigma ** 2)) * np.exp(- (x ** 2 + y ** 2) / (2 * sigma ** 2))\n",
    "    return x, y, z\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "x, y, z = gaussian(1.3)\n",
    "ax.scatter3D(x, y, z, s=1, marker='.')\n",
    "ax.set_xlabel('x'); ax.set_ylabel('y'); ax.set_zlabel('z')\n",
    "ax.set_title('sigma = 1.3')\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "x, y, z = gaussian(3)\n",
    "ax2.scatter3D(x, y, z, s=1, marker='.')\n",
    "ax2.set_title('sigma = 3')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opencvを使用して射影変換を行い本のタイトルを取得してみる\n",
    "カメラで撮影した画像を正面から撮影したかのように補正する「射影変換」の手順を以下にまとめます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像を読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをインポート\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "def display_cv_image(image, format='.png'):\n",
    "    decoded_bytes = cv2.imencode(format, image)[1].tobytes()\n",
    "    display(Image(data=decoded_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の読み込み\n",
    "img = cv2.imread('./data/IMG_4175.jpg')\n",
    "display_cv_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像のサイズが大きすぎるのでアスペクト比を指定してリサイズする\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_to_resolation(img, resolation):\n",
    "    \"\"\"指定した解像度になるように、アスペクト比を固定して、リサイズする。\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    scale = (resolation / (w * h)) ** 0.5\n",
    "    return cv2.resize(img, dsize=None, fx=scale, fy=scale)\n",
    "\n",
    "\n",
    "dst = scale_to_resolation(img, 1280 * 1080)\n",
    "display_cv_image(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 色の二値化と輪郭抽出\n",
    "### 輪郭抽出\n",
    "「輪郭抽出」とは、同じ色を持つ連続する点をつなげた曲線を抽出することです。画像内に任意の形状を持つ物体が存在するかどうか等を判定するために使います。OpenCVの「輪郭抽出」は、二値画像を使い、黒い背景から白い物体の輪郭を検出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#カラーモードをグレーの濃淡に変換します。\n",
    "gray = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY) \n",
    "gray=255-gray\n",
    "# 二値化\n",
    "ret,gray = cv2.threshold(gray,150,255,cv2.THRESH_BINARY)\n",
    "display_cv_image(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のステップは、画像のノイズを除去し、対象の領域のみに焦点を合わせることです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モロフォロジー変換を行い検出対象の領域の輪郭を抽出できるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a closing kernel and apply it to the thresholded image \n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7)) \n",
    "closed = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "display_cv_image(closed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、侵食を4回繰り返し、その後に膨張を4回繰り返します。 侵食は画像から白いピクセルを除去し、小さな塊を除去し、膨張は大きな白い領域を減少させません。 ストレッチ中のぼかし中に削除された小さなスポットは再表示されません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一連の侵食と膨張の後、小さなスポットが正常に削除され本の領域のみが白く塗りつぶされていることがわかります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "closed = cv2.erode(closed, None, iterations = 10) \n",
    "closed = cv2.dilate(closed, None, iterations = 10)\n",
    "display_cv_image(closed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、画像内の本領域の輪郭を見つけましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輪郭抽出\n",
    "contours,image= cv2.findContours(closed, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# 面積の大きいもののみ選別\n",
    "areas = []\n",
    "for cnt in contours:\n",
    "    area = cv2.contourArea(cnt,True)\n",
    "\n",
    "    if abs(area) > 100000:\n",
    "        epsilon = 0.1*cv2.arcLength(cnt,True)\n",
    "        approx = cv2.approxPolyDP(cnt,epsilon,True)\n",
    "        areas.append(approx)\n",
    "\n",
    "cv2.drawContours(dst,areas,-1,(0,255,255),10)\n",
    "display_cv_image(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 射影変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "枠の各点を対応する座標にあわせて射影変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts1 = np.float32(areas[0])\n",
    "pts2 = np.float32([[1018,1358],[1018,0],[0,0],[0,1358]])\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "img = cv2.warpPerspective(dst,M,(1018,1358))\n",
    "display_cv_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 付録:OCRを使用して画像から文字起こしをこなう\n",
    "pythonやOCRを使用するために必要なライブラリのバージョンに互換性がない場合動作しないことがあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import numpy as np\n",
    "#インスタンスを立てます\n",
    "reader = easyocr.Reader(['ch_sim','en']) # this needs to run only once to load the model into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"data/ocr.jpg\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OCR実施、結果を返してもらう。\n",
    "result = reader.readtext(\"data/ocr.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
